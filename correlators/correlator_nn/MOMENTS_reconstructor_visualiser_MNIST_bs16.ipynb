{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist_digits(batches, ki_kf, reconstr, output=True):\n",
    "    batches_to_plot = 5\n",
    "\n",
    "    batch_size = len(batches[0])\n",
    "    print('Batch size:', batch_size)\n",
    "\n",
    "    num_digits = len(batches[0]) * batches_to_plot\n",
    "    print('Num digits: ', num_digits)\n",
    "    \n",
    "    batches = batches[:batches_to_plot]\n",
    "    # Create a grid of subplots with 20 rows and 20 columns\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=16, figsize=(20, 20))\n",
    "    # fig, axes = plt.subplots(num_digits, 20, figsize=(20, 20))\n",
    "\n",
    "    # Flatten the axes array to access the individual subplots easily\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # batches = [batches[i:i+784] for i in range(0, len(batch_correl_list), 784)]\n",
    "\n",
    "    for batch_number, batch in enumerate(batches):\n",
    "        for i, digit in enumerate(batch):\n",
    "            # Convert Torch tensor to a NumPy array and reshape it to (28, 28)\n",
    "            digit_np = digit.view(28, 28).detach().numpy()\n",
    "\n",
    "            # Plot the digit using matplotlib\n",
    "            axes[batch_number*batch_size + i].imshow(digit_np, cmap='gray')\n",
    "            axes[batch_number*batch_size + i].axis('off')\n",
    "\n",
    "    if output:\n",
    "        plt.savefig(f'/Users/as/astapleton_phd/dsb/papers/cumulant_encoder/figs/since_iaifi/final/nn_outputs/MNIST/reconstruction_flavour=vanilla_kikf={ki_kf}_bs=16_reconstr={reconstr}.pdf'.lower())\n",
    "    # # Remove any remaining empty subplots\n",
    "    # for i in range(num_digits, 39):\n",
    "    #     axes[i].axis('off')\n",
    "\n",
    "    # plt.savefig(file)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to calculate cross-entropy divergence\n",
    "def mse_divergence(input_batch, output_batch):\n",
    "    # Flatten the input and output batches\n",
    "    input_flat = input_batch.view(-1)\n",
    "    output_flat = output_batch.view(-1)\n",
    "    \n",
    "    # Compute the cross-entropy loss\n",
    "    loss = F.mse_loss(output_flat, input_flat, reduction='mean')\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=10):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1, 2 and 3pt functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_images_3pt = torch.load('/Users/as/Desktop/reconstructions/moments/MNIST/2pt-1_3pt-0.017/batch_avg_approx_all_1pt_1.0-2pt_0.017-3pt_simpleout')\n",
    "reconstructions_3pt = torch.load('/Users/as/Desktop/reconstructions/moments/MNIST/2pt-1_3pt-0.017/mixed_reconstr_avg_approx_all_1pt_1.0-2pt_0.017-3pt_simpleout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mnist_digits(orig_images_3pt[500:], ki_kf='123', reconstr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reconstructions_3pt = []\n",
    "for batch in reconstructions_3pt:\n",
    "    tidied_batch = [batch[i:i+784] for i in range(0, len(batch), 784)]\n",
    "    new_reconstructions_3pt.append(tidied_batch)\n",
    "# reconstructions_2pt = new_reconstructions_2pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mnist_digits(new_reconstructions_3pt[2200:], ki_kf='123', reconstr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Gaussian blur\n",
    "def gaussian_blur_mnist_digit(flattened_tensor, kernel_size=5, sigma=1.0):\n",
    "    # Reshape the flattened tensor back to its original shape (28x28)\n",
    "    image = flattened_tensor.view(28, 28).unsqueeze(0).float()\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    blurred_image = F.gaussian_blur(image, kernel_size, sigma)\n",
    "\n",
    "    # Remove the extra batch dimension\n",
    "    blurred_image = blurred_image.squeeze(0)\n",
    "\n",
    "    # Flatten the blurred image back to a tensor\n",
    "    blurred_tensor = blurred_image.view(-1)\n",
    "\n",
    "    return blurred_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flattened_mnist_digit(flattened_digit):\n",
    "    # Reshape the flattened tensor to its original shape (28x28)\n",
    "    image = flattened_digit.view(28, 28)\n",
    "\n",
    "    # Plot the digit\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses (Training) - 1,2&3pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the tensor from the saved file\n",
    "file_path = '/Users/as/Desktop/reconstructions/moments/MNIST/2pt-1_3pt-0.017/loss_hist_all_1pt_1.0-2pt_0.017-3pt_simpleout'  # Replace with the path to your saved tensor file\n",
    "loaded_tensor = torch.load(file_path)\n",
    "\n",
    "# Step 2: Convert the tensor to a NumPy array\n",
    "# numpy_array = loaded_tensor.numpy()\n",
    "\n",
    "# Step 3: Plot the data using Matplotlib\n",
    "plt.plot(loaded_tensor[:150])\n",
    "plt.xlabel('Training pass')\n",
    "plt.ylabel('MSE Loss')\n",
    "# plt.title('MSE training loss for 1,2,3pt cumulant decoder')\n",
    "plt.grid(True)\n",
    "plt.savefig('/Users/as/astapleton_phd/dsb/papers/cumulant_encoder/figs/since_iaifi/final/MNIST/MOMENTS_dec_training_loss_123-1_1_0.017.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Step 1: Load the tensor from the saved file\n",
    "file_path = '/Users/as/Desktop/reconstructions/moments/MNIST/2pt-1_3pt-0.017/enc_loss_hist'  # Replace with the path to your saved tensor file\n",
    "loaded_tensor = torch.load(file_path)\n",
    "\n",
    "# Step 2: Convert the tensor to a NumPy array\n",
    "# numpy_array = loaded_tensor.numpy()\n",
    "\n",
    "# Step 3: Plot the data using Matplotlib\n",
    "plt.plot(moving_average(loaded_tensor[:350], 50))\n",
    "plt.xlabel('Training pass')\n",
    "plt.ylabel('Moving average MSE loss')\n",
    "# plt.title('MSE training loss for 1&2pt cumulant encoder')\n",
    "plt.grid(True)\n",
    "plt.savefig('/Users/as/astapleton_phd/dsb/papers/cumulant_encoder/figs/since_iaifi/final/MNIST/MOMENTS_enc_training_loss_123-1_1_0.017.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses (Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the reconstructions are the same tensor repeated |B| times, so we can MSE loss this straight away\n",
    "mse_321 = []\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "for train_pass in range(2000, 2300):\n",
    "    flattened_orig_batch = orig_images_3pt[train_pass].flatten()\n",
    "    flattened_reconstr = torch.concatenate(new_reconstructions_3pt[train_pass], axis=0)\n",
    "    mse_321.append(mse_loss(flattened_orig_batch, flattened_reconstr))\n",
    "print(sum(mse_321)/len(mse_321))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1pt and 2pt functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_images_2pt = torch.load('/Users/as/Desktop/reconstructions/moments/MNIST/2pt-1_3pt-0/batch_avg_approx_all_1pt_1.0-2pt_0.0-3pt_simpleout')\n",
    "reconstructions_2pt = torch.load('/Users/as/Desktop/reconstructions/moments/MNIST/2pt-1_3pt-0/mixed_reconstr_avg_approx_all_1pt_1.0-2pt_0.0-3pt_simpleout')\n",
    "len(reconstructions_2pt)\n",
    "# stiff_reconstructions = torch.load('/home/as/astapleton_phd/dsb/subtle_diffusion/correlators/correlator_nn/reconstr/stiff_reconstr_avg_approx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_mnist_digits(orig_images_2pt, ki_kf='12', reconstr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reconstructions_2pt = []\n",
    "for batch in reconstructions_2pt:\n",
    "    tidied_batch = [batch[i:i+784] for i in range(0, len(batch), 784)]\n",
    "    new_reconstructions_2pt.append(tidied_batch)\n",
    "# reconstructions_2pt = new_reconstructions_2pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_mnist_digits(new_reconstructions_2pt[2300:], ki_kf='12', reconstr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses (Training) - 1&2pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the tensor from the saved file\n",
    "file_path = '/Users/as/Desktop/reconstructions/moments/MNIST/2pt-1_3pt-0/enc_loss_hist'  # Replace with the path to your saved tensor file\n",
    "loaded_tensor = torch.load(file_path)\n",
    "\n",
    "# Step 2: Convert the tensor to a NumPy array\n",
    "# numpy_array = loaded_tensor.numpy()\n",
    "\n",
    "# Step 3: Plot the data using Matplotlib\n",
    "plt.plot(moving_average(loaded_tensor[:180], 50))\n",
    "plt.xlabel('Training pass')\n",
    "plt.ylabel('Moving average MSE loss')\n",
    "# plt.title('MSE training loss for 1&2pt cumulant encoder')\n",
    "plt.grid(True)\n",
    "plt.savefig('/Users/as/astapleton_phd/dsb/papers/cumulant_encoder/figs/since_iaifi/final/MNIST/MOMENTS_enc_training_loss_123-1_1_0.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the tensor from the saved file\n",
    "file_path = '/Users/as/Desktop/reconstructions/moments/MNIST/2pt-1_3pt-0/loss_hist_all_1pt_1.0-2pt_0.0-3pt_simpleout'  # Replace with the path to your saved tensor file\n",
    "loaded_tensor = torch.load(file_path)\n",
    "\n",
    "# Step 2: Convert the tensor to a NumPy array\n",
    "# numpy_array = loaded_tensor.numpy()\n",
    "\n",
    "# Step 3: Plot the data using Matplotlib\n",
    "plt.plot(moving_average(loaded_tensor[4:200], 1))\n",
    "plt.xlabel('Training pass')\n",
    "plt.ylabel('MSE Loss')\n",
    "# plt.title('MSE training loss for 1&2pt cumulant decoder')\n",
    "plt.grid(True)\n",
    "plt.savefig('/Users/as/astapleton_phd/dsb/papers/cumulant_encoder/figs/since_iaifi/final/MNIST/MOMENTS_dec_training_loss_123-1_1_0.0.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses (Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the reconstructions are the same tensor repeated |B| times, so we can MSE loss this straight away\n",
    "mse_21 = []\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "for train_pass in range(2000, 2300):\n",
    "    flattened_orig_batch = orig_images_2pt[train_pass].flatten()\n",
    "    flattened_reconstr = torch.concatenate(new_reconstructions_2pt[train_pass], axis=0)\n",
    "    mse_21.append(mse_loss(flattened_orig_batch, flattened_reconstr))\n",
    "print(sum(mse_21)/len(mse_21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1pt only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_images_1pt = torch.load('/Users/as/Desktop/reconstructions/moments/MNIST/2pt-0_3pt-0/batch_avg_approx_all_1pt_0.0-2pt_0.0-3pt_simpleout')\n",
    "reconstructions_1pt = torch.load('/Users/as/Desktop/reconstructions/moments/MNIST/2pt-0_3pt-0/mixed_reconstr_avg_approx_all_1pt_0.0-2pt_0.0-3pt_simpleout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mnist_digits(orig_images_1pt, ki_kf=1, reconstr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reconstructions_1pt = []\n",
    "for batch in reconstructions_1pt:\n",
    "    tidied_batch = [batch[i:i+784] for i in range(0, len(batch), 784)]\n",
    "    new_reconstructions_1pt.append(tidied_batch)\n",
    "# reconstructions_2pt = new_reconstructions_2pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mnist_digits(new_reconstructions_1pt[900:], ki_kf='1', reconstr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses (Training) -- 1pt Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the tensor from the saved file\n",
    "file_path = '/Users/as/Desktop/reconstructions/moments/MNIST/2pt-0_3pt-0/enc_loss_hist'  # Replace with the path to your saved tensor file\n",
    "loaded_tensor = torch.load(file_path)\n",
    "\n",
    "# Step 2: Convert the tensor to a NumPy array\n",
    "# numpy_array = loaded_tensor.numpy()\n",
    "\n",
    "# Step 3: Plot the data using Matplotlib\n",
    "plt.plot(moving_average(loaded_tensor[:300], 50))\n",
    "plt.xlabel('Training pass')\n",
    "plt.ylabel('Moving average MSE loss')\n",
    "# plt.title('MSE training loss for 1&2pt cumulant encoder')\n",
    "plt.grid(True)\n",
    "plt.savefig('/Users/as/astapleton_phd/dsb/papers/cumulant_encoder/figs/since_iaifi/final/MNIST/MOMENTS_enc_training_loss_123-1_0_0.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Load the tensor from the saved file\n",
    "file_path = '/Users/as/Desktop/reconstructions/moments/MNIST/2pt-0_3pt-0/loss_hist_all_1pt_0.0-2pt_0.0-3pt_simpleout'  # Replace with the path to your saved tensor file\n",
    "loaded_tensor = torch.load(file_path)\n",
    "\n",
    "# Step 2: Convert the tensor to a NumPy array\n",
    "# numpy_array = loaded_tensor.numpy()\n",
    "\n",
    "# Step 3: Plot the data using Matplotlib\n",
    "plt.plot(loaded_tensor[0:150])\n",
    "plt.xlabel('Training pass')\n",
    "plt.ylabel('MSE Loss')\n",
    "# plt.title('MSE training loss for 1 only cumulant decoder')\n",
    "plt.grid(True)\n",
    "plt.savefig('/Users/as/astapleton_phd/dsb/papers/cumulant_encoder/figs/since_iaifi/final/MNIST/MOMENTS_dec_training_loss_123-1_0_0.0.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses (Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the reconstructions are the same tensor repeated |B| times, so we can MSE loss this straight away\n",
    "mse_1 = []\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "for train_pass in range(2000, 2300):\n",
    "    flattened_orig_batch = orig_images_1pt[train_pass].flatten()\n",
    "    flattened_reconstr = torch.concatenate(new_reconstructions_1pt[train_pass], axis=0)\n",
    "    mse_1.append(mse_loss(flattened_orig_batch, flattened_reconstr))\n",
    "print(sum(mse_1)/len(mse_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined MSE losses (val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined MSE validation\n",
    "grainer = 1\n",
    "\n",
    "plt.scatter(range(len(moving_average(mse_1, grainer))), moving_average(mse_1, grainer), label='1pt only')\n",
    "plt.scatter(range(len(moving_average(mse_21, grainer))), moving_average(mse_21, grainer), label='1pt and 2pt')\n",
    "plt.scatter(range(len(moving_average(mse_321, grainer))), moving_average(mse_321, grainer), label='1, 2 and 3pt')\n",
    "plt.xlabel('Validation sample')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/as/astapleton_phd/dsb/papers/cumulant_encoder/figs/since_iaifi/final/MNIST/loss_trifle_all.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(range(len(moving_average(mse_1, grainer))), moving_average(mse_1, grainer), label='1pt only')\n",
    "plt.scatter(range(len(moving_average(mse_21, grainer))), moving_average(mse_21, grainer), label='1pt and 2pt')\n",
    "plt.scatter(range(len(moving_average(mse_321, grainer))), moving_average(mse_321, grainer), label='1, 2 and 3pt')\n",
    "plt.xlabel('Validation sample')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/as/astapleton_phd/dsb/papers/cumulant_encoder/figs/since_iaifi/final/MNIST/loss_trifle_no_13.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(moving_average(mse_1, 100), label='1pt only')\n",
    "plt.plot(moving_average(mse_21, 100), label='1pt and 2pt')\n",
    "plt.plot(moving_average(mse_321, 100), label='1, 2 and 3pt')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
